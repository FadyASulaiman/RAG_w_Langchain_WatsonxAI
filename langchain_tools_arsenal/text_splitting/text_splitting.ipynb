{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Splitting to Enhance Model Responsiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " RAG involves fetching relevant pieces of information from a large dataset and using them to generate accurate and context-aware responses. Without properly split text, the retrieval process can become inefficient, potentially missing critical pieces of information or returning irrelevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install \"langchain==0.2.7\"\n",
    "%pip install \"langchain-core==0.2.20\"\n",
    "%pip install \"langchain-text-splitters==0.2.2\"\n",
    "%pip install \"lxml==5.2.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Courtsey of IBM Skills Network*\n",
    "\n",
    "When using the splitter, you can customize several key parameters to fit your needs:\n",
    "- **separator**: Define the characters that will be used for splitting the text.\n",
    "- **chunk_size**: Specify the maximum size of your chunks to ensure they are as granular or broad as needed.\n",
    "- **chunk_overlap**: Maintain context between chunks by setting the `chunk_overlap` parameter, which determines the number of characters that overlap between consecutive chunks. This helps ensure that information isn't lost at the chunk boundaries.\n",
    "- **length_function**: Define how the length of chunks is calculated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try on a sample document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/YRYau14UJyh0DdiLDdzFcA/companypolicies.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"companypolicies.txt\") as f:\n",
    "    companypolicies = f.read()\n",
    "print(companypolicies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting text by character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\",\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(companypolicies)\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many chunks it did split to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescursively splitting text by characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters, and it tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"].\n",
    "\n",
    "It processes the large text by attempting to split it by the first character, \\n\\n. If the first split by \\n\\n results in chunks that are still too large, it moves to the next character, \\n, and attempts to split by it. This process continues through the list of characters until the chunks are less than the specified chunk size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([companypolicies])\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how many chunks did this text yield this time ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpp',\n",
       " 'go',\n",
       " 'java',\n",
       " 'kotlin',\n",
       " 'js',\n",
       " 'ts',\n",
       " 'php',\n",
       " 'proto',\n",
       " 'python',\n",
       " 'rst',\n",
       " 'ruby',\n",
       " 'rust',\n",
       " 'scala',\n",
       " 'swift',\n",
       " 'markdown',\n",
       " 'latex',\n",
       " 'html',\n",
       " 'sol',\n",
       " 'csharp',\n",
       " 'cobol',\n",
       " 'c',\n",
       " 'lua',\n",
       " 'perl',\n",
       " 'haskell',\n",
       " 'elixir']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "\n",
    "# Let's see the lists of supported languages\n",
    "\n",
    "[e.value for e in Language]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what does it split on by default ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nclass ', '\\ndef ', '\\n\\tdef ', '\\n\\n', '\\n', ' ', '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='def hello_world():'),\n",
       " Document(page_content='print(\"Hello, World!\")'),\n",
       " Document(page_content='# Call the function\\n    hello_world()')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PYTHON_CODE = \"\"\"\n",
    "    def hello_world():\n",
    "        print(\"Hello, World!\")\n",
    "    \n",
    "    # Call the function\n",
    "    hello_world()\n",
    "\"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works perfectly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Markdown documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "md = \"# Foo\\n\\n## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n### Boo \\n\\nHi this is Lance \\n\\n## Baz\\n\\nHi this is Molly\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(md)\n",
    "md_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
    "md_header_splits = markdown_splitter.split_text(md)\n",
    "md_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_string = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <body>\n",
    "        <div>\n",
    "            <h1>Foo</h1>\n",
    "            <p>Some intro text about Foo.</p>\n",
    "            <div>\n",
    "                <h2>Bar main section</h2>\n",
    "                <p>Some intro text about Bar.</p>\n",
    "                <h3>Bar subsection 1</h3>\n",
    "                <p>Some text about the first subtopic of Bar.</p>\n",
    "                <h3>Bar subsection 2</h3>\n",
    "                <p>Some text about the second subtopic of Bar.</p>\n",
    "            </div>\n",
    "            <div>\n",
    "                <h2>Baz</h2>\n",
    "                <p>Some text about Baz</p>\n",
    "            </div>\n",
    "            <br>\n",
    "            <p>Some concluding text about Foo</p>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or by HTML Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLSectionSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <body>\n",
    "        <div>\n",
    "            <h1>Foo</h1>\n",
    "            <p>Some intro text about Foo.</p>\n",
    "            <div>\n",
    "                <h2>Bar main section</h2>\n",
    "                <p>Some intro text about Bar.</p>\n",
    "                <h3>Bar subsection 1</h3>\n",
    "                <p>Some text about the first subtopic of Bar.</p>\n",
    "                <h3>Bar subsection 2</h3>\n",
    "                <p>Some text about the second subtopic of Bar.</p>\n",
    "            </div>\n",
    "            <div>\n",
    "                <h2>Baz</h2>\n",
    "                <p>Some text about Baz</p>\n",
    "            </div>\n",
    "            <br>\n",
    "            <p>Some concluding text about Foo</p>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on = [(\"h1\", \"Header 1\"), (\"h2\", \"Header 2\"), (\"h3\", \"Header 3\")]\n",
    "\n",
    "html_splitter = HTMLSectionSplitter(headers_to_split_on=headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_Langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
